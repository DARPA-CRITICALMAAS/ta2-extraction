{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db85dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    "    wait_incrementing,\n",
    "    wait_fixed,\n",
    "    wait_exponential\n",
    ")  # for exponential backoff\n",
    "import openai\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import re\n",
    "import csv\n",
    "from datetime import date\n",
    "\n",
    "import sys\n",
    "import os\n",
    "## update to your correct path\n",
    "sys.path.append(os.path.expanduser('~/git_folders/ta2-extraction'))\n",
    "from settings import API_KEY\n",
    "import numpy as np\n",
    "# Ignore the specific UserWarning from openpyxl\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='openpyxl')\n",
    "\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=30), stop=stop_after_attempt(16))\n",
    "def chat_completion_with_backoff(**kwargs):\n",
    "    return openai.ChatCompletion.create(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87537ec2-2116-4bce-a8ab-9bf2a7770bf5",
   "metadata": {},
   "source": [
    "## Update File Name For creating Json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7fed3cb-16fd-4f62-8e9e-0a39895efd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_p = \"./reports/mvt_zinc/\"\n",
    "pdf_name = \"Prairie Creek Zn Pb Ag 9-2017 FS.pdf\"\n",
    "curr_path = pdf_p + pdf_name\n",
    "primary_commodity = \"Zinc\"\n",
    "element_sign = \"Zn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0813fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_text_in_pdf(pdf_path, target_string):\n",
    "    page_numbers = []\n",
    "    \n",
    "    # Open the PDF file in binary mode\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        \n",
    "        # Create a PDF reader\n",
    "        pdf = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        # Iterate over each page\n",
    "        for page_num in range(len(pdf.pages)):\n",
    "            page = pdf.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            text_new = ' '.join(text.replace(\"\\t\", \" \").split()).lower()\n",
    "            # Check if target string is in the page's text\n",
    "            if target_string.lower() in text_new:\n",
    "                page_numbers.append(page_num)            \n",
    "    return page_numbers\n",
    "\n",
    "def get_answ(pdf_path,target_strings,model, content, pr, replace_t = False):\n",
    "    all_matching_pages = []\n",
    "    for target_string in target_strings:\n",
    "        matching_pages = search_text_in_pdf(pdf_path, target_string)\n",
    "        all_matching_pages += matching_pages\n",
    "    if len(all_matching_pages)==0:\n",
    "        return({})\n",
    "\n",
    "    res = {}\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf = PyPDF2.PdfReader(file)\n",
    "        all_text = ''\n",
    "        for matching_page in matching_pages:\n",
    "            page = pdf.pages[matching_page]\n",
    "            text = page.extract_text()\n",
    "            all_text = all_text + '/n' + text\n",
    "        if replace_t:\n",
    "            all_text = all_text.replace(\"\\t\", \" \")\n",
    "\n",
    "        response = chat_completion_with_backoff(model=model, temperature=0, max_tokens=100, stop='.', messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": pr+all_text},\n",
    "        ])\n",
    "        res = json.loads(response['choices'][0]['message']['content'])\n",
    "        time.sleep(0.1)\n",
    "    print(f\"Here are all matching_pages to search the answer for: {matching_pages}\")\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c1a5fb",
   "metadata": {},
   "source": [
    "#### Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f829a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"You are a mining assistant, knowledgable in geology and skilled in \n",
    "understanding mining reports. You can extract information about mines, ore and minerals.\"\"\"\n",
    "\n",
    "commodity_pr = \"\"\"You are a geology expert and you are very good in understanding mining reports. You will be given \n",
    "a text from a mining report and you have to find out what are the primary commodities and secondary commodities. \n",
    "The output should be in the following format: \n",
    "{\"primary commodities\": [primary commodity 1, primary commodity 2], \"secondary commodities\": [secondary commodity 1, secondary commodity 2]\n",
    "\n",
    "Note that there could be no primary and secondary commodities mentioned, and in that case you should return None where appropriate.\n",
    "Here is the text: \n",
    "\"\"\"\n",
    "## Deposits\n",
    "deposit_types_p = \"./Deposit classification Scheme.xlsx\"\n",
    "deposit_types = ', '.join(pd.read_excel(deposit_types_p, sheet_name='Deposit classification scheme',engine='openpyxl')['Deposit type'].unique())\n",
    "\n",
    "deposit_pr = \"\"\"You are a geology expert and you are very good in understanding mining reports. You will be given \n",
    "a text from a mining report and you have to find out what are the deposit types in this mine. You can chose only from \n",
    "the provided list of the deposit types. You can chose one or more deposit types. If it is unknown, answer None.\n",
    "The output should be in the following format: {\"deposit types\": [deposit type 1, deposit type 2]}\n",
    "\n",
    "Note that there could be no deposit types mentioned, and in that case you should return None where appropriate.\n",
    "Here is the list of the provided deposit types: \"\"\" + deposit_types + \", None.\" + \"\"\" Here is the text from the report: \n",
    "\"\"\"\n",
    "#### TOC\n",
    "content_toc = \"You are a mining assistant, knowledgable in geology and skilled in understanding mining reports. You can extract information about tables of contents from reports.\"\n",
    "content_pr = \"\"\"You are a documentation expert and you can understand very well the table of contents of the mining reports.\n",
    "You will be provided a table of contents and you need to understand it and return the number and page for each item in a given table of content.\n",
    "The output should be in the following format: \n",
    "{\"text\":[\"number\", \"page\"],  \"text\":[\"number\", \"page\"]}\n",
    "\n",
    "For example: \n",
    "{\"Information Sources and References\":[\"2.5\", \"7\"],\n",
    "\"Reliance on Experts\":[\"3.0\", \"7\"]}\n",
    "\n",
    "If there are no pages visible or you think there is no table of content in a text, return None.\n",
    "Here is the text: \n",
    "\"\"\"\n",
    "### get header\n",
    "content_header = \"\"\"You are a mining assistant, knowledgable in geology and \n",
    "skilled in understanding mining reports. You can extract the header of the section from the\n",
    "given text.\"\"\"\n",
    "content_find = \"\"\"You are a documentation expert and you can understand very well the \n",
    "contents of the mining reports. You will be provided a section of a paper and \n",
    "you need to understand it and see if in the text the term given is used as a header \n",
    "on the given page.\n",
    "The output should only given as \"Yes\" or \"No\". Here is the  \n",
    "\"\"\"\n",
    "## returning from the tables\n",
    "response_example = \"\"\"{'Line1': {'Zone': 'zone', 'Classification': 'classification', 'element Cut-Off': 'cut-off', 'element Tonnage': \n",
    "'tonnage', 'element Grade %': 'element % number' }, 'Line2': {'Zone': 'zone', 'Classification': 'classification', 'element Cut-Off': \n",
    "'cut-off', 'element Tonnage': 'tonnage', 'element Grade %': 'element % number'},...}\"\"\"\n",
    "\n",
    "table_pr = f\"\"\"You are a geology expert and you are very good in understanding mining reports. You will be given \n",
    "a text from a mining report and you have to find out what are the different combinations of Zones which is the name of a location,\n",
    "classification which is either indicated or inferred, cut-off represented as a decimal, tonnage in Tonnes and \n",
    "grade given in % from the tables in the text, which will have most of the given headers that include the words\n",
    "zone, classification or indicated or inferred, cut-off, tonnage, and element %. Please extract the name of the element and place it in the output\n",
    "below without any additional text. Note we only care about the mineral {primary_commodity} represented by {element_sign}.\n",
    "\n",
    "For each line in the table create a nested dictionary that follows this json file format as the response:  \n",
    "{response_example}. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540aacb0",
   "metadata": {},
   "source": [
    "### Get Deposit Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9839da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_types_p = \"./Deposit classification Scheme.xlsx\"\n",
    "deposit_groups = ', '.join(pd.read_excel(deposit_types_p, sheet_name='Deposit classification scheme',engine='openpyxl')['Deposit group'].unique())\n",
    "deposit_types = ', '.join(pd.read_excel(deposit_types_p, sheet_name='Deposit classification scheme',engine='openpyxl')['Deposit type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b300d2bc-704a-4947-882a-b7f61db9866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Here are the deposit groups: {deposit_groups} \\n\\n\")\n",
    "# print(f\"Here are the deposit types: {deposit_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79536ff",
   "metadata": {},
   "source": [
    "## Get commodities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f75b4bce",
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x7f93c8de2820 state=finished raised InvalidRequestError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c4/mhw_ljf90sqg34wt_6z_001w0000gp/T/ipykernel_13196/2229548315.py\u001b[0m in \u001b[0;36mchat_completion_with_backoff\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchat_completion_with_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChatCompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 9811 tokens. Please reduce the length of the messages.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c4/mhw_ljf90sqg34wt_6z_001w0000gp/T/ipykernel_13196/170719204.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mall_comodities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_answ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_p\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpdf_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_strings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommodity_pr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c4/mhw_ljf90sqg34wt_6z_001w0000gp/T/ipykernel_13196/1280971305.py\u001b[0m in \u001b[0;36mget_answ\u001b[0;34m(pdf_path, target_strings, model, content, pr, replace_t)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mall_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         response = chat_completion_with_backoff(model=model, temperature=0, max_tokens=100, stop='.', messages=[\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mall_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x7f93c8de2820 state=finished raised InvalidRequestError>]"
     ]
    }
   ],
   "source": [
    "target_strings = [\"commodit\"]\n",
    "model = 'gpt-3.5-turbo'\n",
    "\n",
    "all_comodities = {}\n",
    "res = get_answ(pdf_p + pdf_name,target_strings,model, content, commodity_pr)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a5f34b",
   "metadata": {},
   "source": [
    "## Get deposit types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18cbe1ae-fb85-4e0d-8dee-5b43207676c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Residual placer tin', 'Residual placer lead', 'Fluvial placer gold', 'Fluvial placer PGE', 'Fluvial placer tin', 'Fluvial placer niobium- tantalum', 'Fluvial placer tungsten', 'Fluvial placer REE', 'Fluvial placer diamond', 'Fluvial placer gemstones', 'Fluvial placer garnet', 'Heavy mineral sands', 'Shoreline placer gold', 'Paleoplacer heavy mineral sands', 'Paleoplacer tin', 'Paleoplacer gold ± uranium', 'Bauxite', 'Karst bauxite', 'Laterite nickel', 'Carbonatite laterite REE', 'Laterite magnesite', 'Residual clay', 'Underclay', 'over- clay', 'Ion adsorption REE', 'Supergene silver', 'Supergene lead', 'Supergene uranium', 'Supergene vanadium', 'Supergene gold', 'Supergene zinc', 'Supergene copper', 'Supergene manganese', 'Supergene iron', 'Exotic copper', 'Paleochannel iron', 'Sandstone uranium', 'Carbonate uranium', 'Coal/peat/bog uranium', 'Calcrete uranium', 'Nodular magnesite', 'Marine evaporite gypsum', 'Marine evaporite salt', 'Marine evaporite potash', 'Marine evaporite magnesite', 'Lacustrine evaporite trona', 'Lacustrine evaporite salt', 'Lacustrine evaporite potash', 'Lacustrine evaporite carnallite- bischofite', 'Lacustrine evaporite borate', 'Lacustrine evaporite magnesite', 'Lacustrine evaporite nitrate', 'Marine brine potash (±Mg', 'Li', 'and so on)', 'Lacustrine brine potash', 'Lacustrine brine lithium', 'Lacustrine zeolite (± Li', 'B)', 'Lacustrine clay lithium', 'Black shale va- nadium ± Mo ± Ni', 'Black shale nickel ± Mo- PGE', 'Black shale gold', 'Black shale uranium', 'Phosphorite', 'Superior-type banded iron formation', 'Oolitic iron formation', 'Lacustrine iron formation', 'Superior-type banded manganese', 'Sedimentary manganese', 'Crust manganese', 'Nodule manganese', 'Lacustrine manganese', 'Unconformity- related ura- nium', 'Unconformity- related REE', 'Collapse breccia pipe uranium', 'Volcanic-hosted copper', 'Sediment-hosted copper ± Co', 'Siliciclastic-mafic zinc-lead', 'Siliciclastic-mafic\\n barite', 'Siliciclastic- carbonate zinc-lead', 'Irish-type sediment- hosted zinc- lead', 'Kipushi-type sediment- hosted copper- zinc-lead', 'MVT zinc-lead', 'MVT barite', 'MVT fluorspar', 'MVT strontium', 'Sandstone-hosted zinc-lead', 'Non-sulfide zinc-lead ± Mn', 'Vein five-element', 'Hypozonal orogenic gold', 'Mesozonal orogenic gold', 'Epizonal orogenic gold', 'Epizonal orogenic antimony ± gold', 'Epizonal orogenic mercury', 'Orogenic silver-lead- zinc-copper- antimony', 'Orogenic copper ± gold', 'Orogenic graphite', 'Metamorphic graphite', 'Metamorphic kyanite', 'Low Iron alkali-calcic', 'Albitite-hosted uranium', 'Ferroan carbonate polymetallic', 'Iron sulfide polymetallic', 'Iron silicate polymetallic', 'Iron oxide poly- metallic', 'Iron oxide uranium', 'Iron oxide gold', 'Hematite- dominant IOCG', 'Magnetite- dominant IOCG', 'Hematite- dominant IOA', 'Magnetite- dominant IOA', 'Mafic-ultramafic VMS', 'Mafic-siliciclastic\\n VMS', 'Bimodal-mafic\\n VMS', 'Bimodal felsic VMS', 'Felsic-siliciclastic VMS', 'Algoma-type banded iron formation', 'Volcanogenic manganese', 'Low-sulfidation (LS) epither- mal gold-silver', 'Intermediate- sulfidation (IS) epithermal silver-gold ± Zn', 'Pb', 'Cu', 'Sn', 'Mn', 'High-sulfidation (HS) epithermal silver-gold ± Cu', 'Alkalic epithermal gold ± Ag', 'Epithermal mercury', 'Epithermal beryllium', 'Epithermal uranium', 'Vein ± replacement nickel', 'Vein cobalt ± Ni', 'Vein copper', 'Vein tin', 'Vein tungsten', 'Vein tin polymetallic', 'Vein fluorite', 'Vein polymetallic', 'Breccia pipe copper', 'Breccia pipe gold', 'Breccia pipe molybdenum', 'Breccia pipe REE', 'Carlin-type gold', 'Distal- disseminated silver-gold', 'Replacement polymetallic', 'Replacement gold-silver', 'Replacement tin', 'Replacement copper', 'Replacement zinc-lead', 'Replacement manganese', 'Replacement magnesium', 'Replacement fluorite', 'Skarn iron', 'Skarn copper', 'Skarn tungsten ± Mo', 'Skarn tin ± copper ± Mo', 'Skarn gold ± copper ± tungsten', 'Skarn zinc-lead-\\n silver', 'Skarn molybdenum', 'Skarn beryllium- fluorite', 'Skarn uranium- REE', 'Porphyry copper ± gold', 'Porphyry copper- molybdenum', 'Porphyry gold ± copper', 'Climax-type porphyry molybdenum', 'Low-fluorine porphyry molybdenum', 'Porphyry tungsten', 'Porphyry tin', 'Greisen tin ±W-Mo', 'Greisen tungsten- molybdenum\\n ±Bi', 'Greisen beryllium\\n ±Li', 'Reduced intrusion- related gold', 'Oxidized intrusion- related gold', 'Simple pegmatite', 'LCT pegmatite', 'NYF pegmatite', 'Abyssal pegmatite REE', 'Carbonatite REE', 'Carbonatite niobium', 'Peralkaline igneous HFSE- REE', 'Apatite- nepheline- titanite intrusion', 'Apatite intrusion REE', 'Kimberlite diamond', 'Komatiite nickel-copper-PGE', 'U-M layered intrusion chromium', 'U-M layered intrusion nickel- copper-PGE', 'U-M layered intrusion PGE', 'U-M layered intrusion\\n iron-titanium- vanadium', 'U-M intrusion nickel-copper- PGE', 'U-M conduit nickel-copper- PGE', 'Ophiolite chro- mium', 'Ophiolite nickel-\\n copper-PGE', 'Arc U-M intrusion titanium- vanadium', 'Arc U-M intru- sion nickel- copper-PGE', 'Anorthosite mas- sif titanium', 'Anorthosite conduit nickel- copper-PGE', 'Impact U-M intrusion nickel- copper-PGE']\n"
     ]
    }
   ],
   "source": [
    "dtype_list = deposit_types.split(\", \")\n",
    "print(dtype_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a43a9-19d4-464a-97f4-e4eceed4522b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dtype in dtype_list:\n",
    "    # print(f\"Looking at deposit type {dtype} \\n\")\n",
    "    pages = search_text_in_pdf(pdf_p+pdf_name, dtype)\n",
    "    if len(pages) > 0:\n",
    "        print(dtype + \": \" + pages)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5243948",
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x7f93a9d5c4c0 state=finished raised InvalidRequestError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c4/mhw_ljf90sqg34wt_6z_001w0000gp/T/ipykernel_13196/2229548315.py\u001b[0m in \u001b[0;36mchat_completion_with_backoff\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchat_completion_with_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChatCompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 5976 tokens. Please reduce the length of the messages.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c4/mhw_ljf90sqg34wt_6z_001w0000gp/T/ipykernel_13196/552866093.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Deposit type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_answ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_p\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpdf_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_strings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeposit_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/c4/mhw_ljf90sqg34wt_6z_001w0000gp/T/ipykernel_13196/1280971305.py\u001b[0m in \u001b[0;36mget_answ\u001b[0;34m(pdf_path, target_strings, model, content, pr, replace_t)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mall_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         response = chat_completion_with_backoff(model=model, temperature=0, max_tokens=100, stop='.', messages=[\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mall_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x7f93a9d5c4c0 state=finished raised InvalidRequestError>]"
     ]
    }
   ],
   "source": [
    "target_strings = [\"Deposit type\"]\n",
    "res = get_answ(pdf_p + pdf_name,target_strings,model, content, deposit_pr, replace_t=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d1a52-c8c9-4e47-a35d-fee696b1f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "deposit_types = {}\n",
    "deposit_types['deposit types'] = []\n",
    "for dep in res['deposit types']:\n",
    "    deposit_types['deposit types'].append({\"id\": idx, \"name\": dep})\n",
    "    idx +=1\n",
    "print(deposit_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d36b00",
   "metadata": {},
   "source": [
    "## Get TOC\n",
    "\n",
    "old content_pr: \n",
    "content_pr = \"\"\"You are a documentation expert and you can understand very well the table of contents of the mining reports.\n",
    "You will be provided a table of contents and you need to understand it and return the number and page for each item in a given table of content.\n",
    "The output should be in the following format: \n",
    "{[\"number\", \"text\", \"page\"],\n",
    "[\"number\", \"text\", \"page\"]}\n",
    "\n",
    "For example: \n",
    "{[\"2.5\", \"Information Sources and References\", \"7\"],\n",
    "[\"3.0\", \"Reliance on Experts\", \"7\"]}\n",
    "\n",
    "If there are no pages visible or you think there is no table of content in a text, return None. \n",
    "Here is the text\n",
    "\n",
    "#### Overall Steps\n",
    "1. Get the table of contents\n",
    "2. From the table of contents dictionary, look for Mineral Resource or whichever term you need. \n",
    "3. Create the term header and from the given start page look for where we have the term header to get the offset\n",
    "4. With the offset, find where the tables are starting from that page to maybe the next section(?) or last page we see that table\n",
    "\n",
    "Notes: need to determine how to stop duplicates being added. Need to determine best way to create a search term\n",
    "within the document. Need to figure out best extraction method before adding to the csv.\n",
    "\n",
    "- Should also think about best way to search for the header: i think we can get the term section number and then the term from the TOC. Can use this to search for the start page. Do not need to do chat GPT. Problems with current. If pages are not always identical or if there is a spacing problem. Should try doing a cosine or fix the paper to dismiss spacing issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb2fec-1f84-46a7-9f19-371ca8574ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_json_compatible(string):\n",
    "    try:\n",
    "        json.loads(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def get_toc(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf = PyPDF2.PdfReader(file)\n",
    "\n",
    "        # scan first n=8 pages and get the TOC\n",
    "        all_res = {}\n",
    "        for i in range(0,8):\n",
    "            print(f\"on page {i}\")\n",
    "            page = pdf.pages[i]\n",
    "            text = page.extract_text()\n",
    "            model = 'gpt-4'\n",
    "            response = chat_completion_with_backoff(model=model, temperature=0, max_tokens=2000, stop='', messages=[\n",
    "                {\"role\": \"system\", \"content\": content_toc},\n",
    "                {\"role\": \"user\", \"content\": content_pr + text},\n",
    "                ])\n",
    "            res = response['choices'][0]['message']['content']\n",
    "            # print(res)\n",
    "            if is_json_compatible(res):\n",
    "                ans = json.loads(res)\n",
    "                for key in ans.keys():\n",
    "                    all_res[key] = ans[key]\n",
    "    return all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720e2e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_res = get_toc(curr_path)\n",
    "print(all_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4b879c-979b-42da-91f2-4a93f12d77e7",
   "metadata": {},
   "source": [
    "## Section to Search or Filter the document for the Mineral Resource Header\n",
    "Note: We are assuming that the report uses the NUMBER SECTION + TITLE in the report to refer to the start of a new section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f62104",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to get offset \n",
    "def get_offset(term, start_page, curr_file):\n",
    "        ## need to look for term \n",
    "        # print(start_page)\n",
    "        with open(curr_file, 'rb') as file:\n",
    "            pdf = PyPDF2.PdfReader(file)\n",
    "            \n",
    "            for i in range(start_page-1, start_page + 10):\n",
    "                # print(f\"On page {i}\")\n",
    "                page = pdf.pages[i]\n",
    "                text = page.extract_text()\n",
    "                text_new = ' '.join(text.replace(\"\\t\", \" \").split()).lower()\n",
    "                model = 'gpt-4'\n",
    "                response = chat_completion_with_backoff(model=model, temperature=0, max_tokens=2000, stop='', messages=[\n",
    "                    {\"role\": \"system\", \"content\": content_header},\n",
    "                    {\"role\": \"user\", \"content\": content_find+f\"Term: {term} and here is the text\" + text_new},\n",
    "                    ])\n",
    "                # print(text)\n",
    "                res = response['choices'][0]['message']['content']\n",
    "                if res == \"Yes\":\n",
    "                    # print(text)\n",
    "                    return (start_page, i, i-start_page)\n",
    "            return (start_page,None, None)\n",
    "    \n",
    "def is_int(value):\n",
    "    try:\n",
    "        int(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def find_header_pg(pdf_path, target_string):\n",
    "    \n",
    "    # Open the PDF file in binary mode\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        \n",
    "        # Create a PDF reader\n",
    "        pdf = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        # Iterate over each page\n",
    "        for page_num in range(7, len(pdf.pages)):\n",
    "            page = pdf.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            text_new = ' '.join(text.replace(\"\\t\", \" \").split()).lower()\n",
    "            # Check if target string is in the page's text\n",
    "            if target_string.lower() in text_new:\n",
    "                return page_num\n",
    "        return 0\n",
    "            \n",
    "def get_correct_pages(term_list, curr_path, use_section=True):\n",
    "    correct_pages = {}\n",
    "    \n",
    "    for inner_dict in term_list:\n",
    "        for title in inner_dict:\n",
    "            if use_section:\n",
    "                header_term = inner_dict[title][0] + \" \" + title\n",
    "                new_pg = find_header_pg(curr_path, header_term)\n",
    "            else:\n",
    "                new_pg = find_header_pg(curr_path, title)\n",
    "            correct_pages[title] = new_pg\n",
    "    return correct_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506baa1-306a-4052-92ff-ef041e2d8cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mineral_res = []\n",
    "for key in all_res.keys():\n",
    "    if \"mineral resource\" in key.lower():\n",
    "        mineral_res.append({key.lower(): all_res[key]})\n",
    "\n",
    "print(mineral_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b65fcf-a442-48ec-a3de-e76e37c564bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "term = list(mineral_res[0].keys())[0]\n",
    "section = mineral_res[0][term][0]\n",
    "header_term = section + \" \" + term\n",
    "og_pg =  mineral_res[0][term][1]\n",
    "\n",
    "if is_int(og_pg):\n",
    "    print(\"Using Chat GPT to Find OFFSET\")\n",
    "    og_pg = int(og_pg)\n",
    "    ## Note need to use header_term to find correct section\n",
    "    og_pg, new_pg, offset = get_offset(header_term, og_pg, curr_path)\n",
    "    print(f\"Found the offset: {offset}\")\n",
    "\n",
    "    correct_pages = {}\n",
    "    if offset != None:\n",
    "        for inner_dict in mineral_res:\n",
    "            for title in inner_dict:\n",
    "                old_pg = inner_dict[title][1]\n",
    "                new_pg = int(old_pg) + offset\n",
    "                correct_pages[title] = new_pg\n",
    "    else:\n",
    "        print(\"Using String Matching to Find OFFSET\")\n",
    "        correct_pages = get_correct_pages(mineral_res, )\n",
    "else:\n",
    "    print(\"Using String Matching to Find OFFSET\")\n",
    "    correct_pages = get_correct_pages(mineral_res, curr_path)\n",
    "    \n",
    "## trying to see if there were missing values\n",
    "for key in correct_pages:\n",
    "    if correct_pages[key] == 0:\n",
    "        # try updating any keys that weren't updated\n",
    "        addn_dict = get_correct_pages(mineral_res, curr_path, use_section = False)\n",
    "        for key in addn_dict:\n",
    "            correct_pages[key] = addn_dict[key]\n",
    "            \n",
    "print(correct_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281bcb80-61fb-410e-b973-6e4ddf9ecf05",
   "metadata": {},
   "source": [
    "## Searching within the table:\n",
    "- Classification (Indicated, Inferred...)\n",
    "- Cut-off\n",
    "- Tonnage\n",
    "- Grade\n",
    "\n",
    "### always look in mineral resource\n",
    "- look at the page number offsets\n",
    "- compare to the TOC\n",
    "- Find summary and the do the offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd270d0-6757-4667-bd0d-99720901b68b",
   "metadata": {},
   "source": [
    "## Use Chat GPT to search for the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1506b-d125-4891-a5f4-d8c2ee303f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_tables(pdf_path, start_page):\n",
    "    uniq_dict = {}\n",
    "    for page_num in range(start_page, start_page+4):\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf = PyPDF2.PdfReader(file)\n",
    "            page = pdf.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            model = 'gpt-4'\n",
    "            #model = 'gpt-3.5-turbo'\n",
    "            response = chat_completion_with_backoff(model=model, temperature=0, max_tokens=2000, stop='', messages=[\n",
    "                {\"role\": \"system\", \"content\": content},\n",
    "                {\"role\": \"user\", \"content\": table_pr + text},\n",
    "                ])\n",
    "            res = response['choices'][0]['message']['content']\n",
    "            match = re.search(r'\\{.*\\}', res, re.DOTALL)\n",
    "            if match:\n",
    "                extracted_content = match.group(0).replace(\"'\", '\"')\n",
    "                # print(extracted_content)\n",
    "                if is_json_compatible(extracted_content):\n",
    "                    ans = json.loads(extracted_content)\n",
    "                    for inner_dict in ans.values():\n",
    "                        inner_dict['page_num']= page_num + 1\n",
    "                        if tuple(inner_dict.values()) in uniq_dict.keys():\n",
    "                            pass\n",
    "                        else:\n",
    "                            uniq_dict[tuple(inner_dict.values())] = \"seen\"\n",
    "                    \n",
    "            # else:\n",
    "            #     print(\"No match found.\") \n",
    "    return uniq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83dd7cb-f255-4d2d-9268-b5919c4f2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_dict = {}\n",
    "for header in correct_pages:\n",
    "    temp = search_for_tables(curr_path, correct_pages[header])\n",
    "    print(f\"\\n Here is the dictionary from header {header}: \\n {temp}\\n\")\n",
    "    for key in temp:\n",
    "        if key in overall_dict:\n",
    "            pass\n",
    "        else:\n",
    "            overall_dict[key] = 'seen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd515b7-9cd5-42db-9c09-4c8d0ea759ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dc8936-ceba-4962-82f9-cb21b831140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mineral_inventory = {}\n",
    "mineral_inventory['MineralInventory'] = []\n",
    "idx = 0\n",
    "\n",
    "    \n",
    "for inner_sec in overall_dict:\n",
    "    inner_dict = {}\n",
    "    grade_dict = {}\n",
    "    page_ref = {}\n",
    "    zone = inner_sec[0]\n",
    "    category = inner_sec[1]\n",
    "    cut_off = inner_sec[2]\n",
    "    tonnage = str(inner_sec[3]).replace(',', '')\n",
    "    grade = inner_sec[4]\n",
    "    page_num = inner_sec[5]\n",
    "    contained_metal = int(tonnage) * float(grade)\n",
    "    page_ref['page'] = page_num\n",
    "    grade_dict['grade_unit'] = 'percent'\n",
    "    grade_dict['grade_value'] = grade\n",
    "    inner_dict[\"id\"] = idx\n",
    "    inner_dict['commodity'] = primary_commodity\n",
    "    inner_dict['category'] = category\n",
    "    inner_dict['ore'] = tonnage\n",
    "    inner_dict['grade'] = grade_dict\n",
    "    inner_dict['cutoff_grade'] = cut_off\n",
    "    inner_dict['contained_metal'] = contained_metal\n",
    "    inner_dict['reference'] = page_ref\n",
    "    inner_dict['date'] = date.today().strftime(\"%Y-%m-%d\")\n",
    "    mineral_inventory['MineralInventory'].append(inner_dict)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0b1d9-666d-464b-9967-2fc7e47c3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mineral_inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a254d3-1c1e-4788-befe-e24d0e3fd384",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create json file\n",
    "combined = [deposit_types, mineral_inventory]\n",
    "with open(f\"{pdf_name[:-4]}.json\", \"w\") as outfile:\n",
    "    json.dump(combined, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c0c079-a0db-43bf-8823-a0925242ab46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
